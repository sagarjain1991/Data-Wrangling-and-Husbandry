---
title: "HW8"
author: "Sagar Jain"
date: "30 March 2020"
output: html_document
---

```{r setup, include=FALSE}

library(tidyverse)
library(rvest)
library(lubridate)
library(stringr)
library(httr)
library(curl)
library(jsonlite)
library(kableExtra)
library(printr)
library(tidytext)
library(wordcloud)
library(dplyr)
library(pool)
library(RSQLite)
library(RMySQL)

source("api-keys.R")

```
### Exercise 2   


-----

Look at the API documentation at https://dev.socrata.com/foundry/healthdata.nj.gov/9hse-wixk.   



#### Part a) 
##### _Question:_   

Write a function that will use the API and then generate a plot of the rate of heart disease over time by year. Set the default to all races, but include an option to specify the race. To get ggplot2 to generate a plot from within a function, wrap the nal object in the print() function. Be sure to include in your RMarkdown a plot generated by your
function, using the default of all races and another using one specific race.   

----
##### _Answer:_   


First, I get the table from the url, and take a look at its structure.

```{r prelim_2a, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
url <- "https://healthdata.nj.gov/resource/5dpz-3wxj.json"

heart_disease <- jsonlite::fromJSON(url)

head(heart_disease)
  
```   
-----   

Now, I implement the function, first by cleaning the data set, and then by filtering only the rows I need for the plot. In the function, as it was specified, __\"All\"__ is the default selection if nothing is passed through.   
Finally, I plot the result and also use _print()_ for the final object.   


```{r part_2a1, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
heart_disease_by_year <-function(race_selected = "All")
{
  url <- "https://healthdata.nj.gov/resource/5dpz-3wxj.json"
  
  heart_disease <- jsonlite::fromJSON(url)
  
  heart_disease.clean <- heart_disease %>% 
    mutate(heartdisease = as.numeric(heartdisease)) %>%
    mutate(year = as.numeric(year))
  
  heart_disease.plot <- heart_disease.clean  %>%
    subset(!is.na(heartdisease)) %>%
    filter(race == race_selected)
  
  min_plot <- min(heart_disease.plot$heartdisease)
  max_plot <- max(heart_disease.plot$heartdisease)
  
  heart_disease.plot <- heart_disease.clean  %>%
    subset(!is.na(heartdisease)) %>%
    filter(year != "Target") %>%
    filter(race == race_selected)
  
  
  print(heart_disease.plot)  
  
  ggplot(heart_disease.plot, aes(year, heartdisease)) + 
    geom_point() + 
    geom_smooth() +
    ylim(min_plot, max_plot) +
    ggtitle(paste("Heart Disease vs Year. Race selection:", race_selected)) +
    xlab("Year") +
    ylab("Heart Disease")
}
```


----    


When the function is ready, I called it for some races to show how it works


-----   


```{r part_2a2, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
heart_disease_by_year()
heart_disease_by_year("Hispanic")
```

-----   


### Exercise 3   


-----

The __New York Times__ has a nice set of APIs, described at https://developer.nytimes.com/apis.    

----   
##### _Answer:_     


First, I got myself an API key to do the exercise. Then, I searched for the url that I needed to call the APIs.  
After that, for each of the JSONs obtained, first I looked for the correct variable name to get the titles.   
Next, I **anti_join** them with the stop words, and count how many of the remaining words where in all of the titles. In this step, I added a filter to keep out the words that were actually numbers.    
Finally, I did a bar plot of the most common non-stop-words in the titles for each of the API calls.    

---- 

First, for *Most Popular articles*:  


```{r part_3bMostPop, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
url.MostPopular <- paste0(
    "https://api.nytimes.com/svc/mostpopular/v2/viewed/1.json?api-key=", 
    api.key.NYTimesMostPop
  )
json_result.MostPopular <- url.MostPopular %>% curl() %>% readLines()

MostPopular.titles <-json_result.MostPopular %>% fromJSON() %>% 
  .$results %>% .$title 

MostPopular.stop_words <-
  tibble(title = MostPopular.titles) %>%
  unnest_tokens(word, title) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE) %>%
  filter(!grepl("\\d+\\.*\\d*", word)) %>%
  arrange(desc(n)) %>%
  head(10)

ggplot(MostPopular.stop_words, aes(word, n)) +
  ggtitle("Top 10 Most common non-stop words in the titles of the Most Popular articles") + 
  xlab("Word in title") +
  ylab("Count") +
  geom_bar(stat="identity", fill = "dodgerblue4") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
````   

----   

Then, for *World Top Stories*:  


```{r part_3bWorldTop, error = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
url.WorldTop <- paste0(
  "https://api.nytimes.com/svc/topstories/v2/world.json?api-key=", 
  api.key.NYTimesTopStories
)

json_result.WorldTop <- 
  url.WorldTop %>% fromJSON()
names(json_result.WorldTop)
names(json_result.WorldTop$results)
WorldTop.titles <- json_result.WorldTop %>% .$results %>% .$title 

WorldTop.stop_words <-
  tibble(title = WorldTop.titles) %>%
  unnest_tokens(word, title) %>%
  anti_join(stop_words) %>%
  filter(!grepl("\\d+\\.*\\d*", word)) %>%  #I add this filter so I keep only words and not numbers
  count(word, sort = TRUE) %>%
  arrange(desc(n)) %>%
  head(10)

ggplot(WorldTop.stop_words, aes(word, n)) +
  geom_bar(stat="identity", fill = "dodgerblue4") +
  ggtitle("Top 10 Most common non-stop words in the titles of the World Top Stories articles") + 
  xlab("Word in title") +
  ylab("Count") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
````   

-----   

### Question 3 Data Base Connection

```{r part_4}

my_db <- dbPool(RMySQL::MySQL(), dbname = "shinydemo", host = "shiny-demo.csa7qlmguqrf.us-east-1.rds.amazonaws.com", username = "guest", password = "guest")
city <- tbl(my_db, "City")
country <- tbl(my_db, "Country")
country_language <- tbl(my_db, "CountryLanguage")



````  

*(a)* By joining the City and Country tables on the code variable (slightly different names in each table, i.e., Code and CountryCode), create a new table containing only the name
of the city, the continent, the region, and the population of the city (not the population of the country).

```{r part_4a}

city <- collect(city %>% select(Name, Population, CountryCode))
country <- collect(country %>% select(Code, Region, Continent))
join_city_and_country <- inner_join(city, country, by = c("CountryCode" = "Code")) 
head(join_city_and_country)


````  

*(b)* Restricting to North America, make boxplots of population by region.
```{r part_4b}

north_america <- join_city_and_country %>% filter(Continent == 'North America')
ggplot(data = north_america, mapping = aes(x = Region, y = Population)) + geom_boxplot()  + ggtitle("Population By Region Plot") + xlab("Region") + ylab("Population")


```` 


*(c)* Taking advantage of the nest() function, show the 5 largest cities in each region in North America.

```{r part_4c}

topFive <- function(x)
{
    x <- x %>% arrange(desc(Population)) %>% head()
}
group_by_region <- north_america %>% group_by(Region) %>% nest() 
#arrange(Region, desc(Population))
group_by_region <- group_by_region %>% mutate(top5 = map(data, topFive))
five_largest_cities_per_region <- group_by_region %>% select(Region, top5) %>% unnest()
five_largest_cities_per_region

```` 


### Question 5 R has a built-in dataframe called ChickWeight.


```{r part_5}

chick <- ChickWeight
head(ChickWeight)
```` 
*(a)* Using nest(), construct a 50x3 dataframe with columns corresponding to the chick id, the chick diet, and dataframes of each chick's data.

```{r part_5a}

chick_df <- chick %>% group_by(Chick, Diet) %>% nest()
head(chick_df)
```` 
*(b)* Create a new column consisting of an lm model for each chick, where the regression is weight ~ Time.


```{r part_5b}
chick_lm <-function(df)
{
  lm(weight ~ Time, data = df)
}

chick_df <- chick_df %>% mutate(lm_fit = map(data, chick_lm))

head(chick_df)

```` 
*(c)* Add columns to the dataframe giving the slope and intercept for each chick (the broom package might be helpful, but it's not the only way).


```{r part_5c}
library(modelr)
chick_df <- chick_df %>% mutate(intercept = map(lm_fit, tidy))
chick_df_unnested <- unnest(chick_df, intercept)
intercept <- chick_df_unnested %>% filter(term=='(Intercept)') %>% select(estimate)
slope <- chick_df_unnested %>% filter(term=='Time') %>% select(estimate)
chick_df$intercept <- intercept$estimate
chick_df$slope <- slope$estimate
head(chick_df)

```` 

*(d)* Make a scatterplot of slope (vertical axis) and intercept (horizontal axis) of the linear models colored by Diet.

```{r part_5d}
ggplot(chick_df, aes(intercept, slope, color = Diet)) + geom_point() + ggtitle("Slope v/s Intercept color coded by Diet") + xlab("Intercept") + ylab("Slope")

```` 

